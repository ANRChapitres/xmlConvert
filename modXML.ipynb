{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1049,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import fnmatch\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from bs4 import Comment\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1050,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def divRend(soup, listAtt, name):\n",
    "    for att in listAtt:\n",
    "        for a in soup.find_all('div',{\"rend\" : att}):\n",
    "            a.attrs.clear()\n",
    "            a.name=name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1051,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def defChap():\n",
    "    for a in xmlSoup.find_all('div',{\"type\" : \"section\"},{\"n\":True}):\n",
    "        check=False\n",
    "        sectionTitle=a[\"n\"]\n",
    "        p = re.compile('^[IVXL]+$')\n",
    "        for potBook in listBook:\n",
    "            if potBook in sectionTitle:\n",
    "                a.attrs.clear()\n",
    "                a.name=\"book\"\n",
    "                a[\"type\"]=\"book\"\n",
    "                a[\"title\"]=sectionTitle\n",
    "                check=True\n",
    "        for potPart in listPart:\n",
    "            if potPart in sectionTitle:\n",
    "                a.attrs.clear()\n",
    "                a.name=\"part\"\n",
    "                a[\"type\"]=\"part\"\n",
    "                a[\"title\"]=sectionTitle\n",
    "                check=True\n",
    "        for potChap in listChap:\n",
    "            if potChap in sectionTitle or p.search(sectionTitle):\n",
    "                a.attrs.clear()\n",
    "                a.name=\"chapter\"\n",
    "                a[\"type\"]=\"chapter\"\n",
    "                a[\"title\"]=sectionTitle\n",
    "                check=True\n",
    "        if check==False:\n",
    "            a.attrs.clear()\n",
    "            a.name=\"chapter\"\n",
    "            a[\"type\"]=\"undefined\"\n",
    "            a[\"title\"]=sectionTitle\n",
    "    for a in xmlSoup.find_all('div',{\"type\" : \"chapter\"}):\n",
    "        a.attrs.clear()\n",
    "        if a.findChild('head'):\n",
    "            a.name=\"chapter\"\n",
    "            title=a.find('head').string\n",
    "            if (title==None):\n",
    "                a.extract()\n",
    "            else:\n",
    "                for book in listBook:\n",
    "                    if book in title:\n",
    "                        a.name=\"book\"\n",
    "                a.attrs.clear()\n",
    "                a[\"title\"]=title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1052,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def elemExtract(elems):\n",
    "    for elem in elems:\n",
    "        [x.extract() for x in xmlSoup.findAll(elem)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1053,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def quote(soup,listVerse,att):\n",
    "    for verse in listVerse:\n",
    "        for a in soup.find_all('div',{\"rend\" : verse}):\n",
    "            txt=a.text\n",
    "            a.attrs.clear()\n",
    "            a.name=att\n",
    "            a.string=txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1054,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ns = {'dc': 'http://purl.org/dc/elements/1.1/'}\n",
    "rends={'pindent','blocktextpblocktext','frontmatter',\n",
    "         'captionmatter','realspc',\n",
    "         'calibre','calibrecalibre','sepetoile','chapter',\n",
    "         'titlechapter','pcbr','calibretitpartl','titpartl',\n",
    "        'titlesection','part','chapn','schap','dev','pre',\n",
    "        'pagecopyright','subtitlechapter','pindentinverse','pc',\n",
    "      'titchapl'}\n",
    "salutes={'dedicace','indentdedicaces'}\n",
    "quotes={'cita','citation',\n",
    "        'poetrypoetryintfigureadvertisementfigureadvertisement'}\n",
    "verses={'poetrypoetryintcalibrestropint','citastroplg',\n",
    "        'poetrycontainerpoetrystanza','poemstanza',\n",
    "        'poetrycontainerpoetrystanza','poetrypoetryintstropstrop',\n",
    "        'poem'}\n",
    "toRem={'meta','dc:contributor','dc:description','dc:publisher',\n",
    "      'dc:language','dc:identifier','dc:rights','dc:subjects',\n",
    "      'graphic','?xml-model'}\n",
    "listChap={\"chapitre\",\"Chapitre\",\"Chapitre\",\n",
    "              \"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"0\"}\n",
    "listBook={\"livre\",\"Livre\",\"LIVRE\"}\n",
    "listPart={\"Partie\",\"partie\",\"Partie\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1055,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parcours des fichiers\n",
    "for idx, fileTemp in enumerate(fnmatch.filter(os.listdir('/home/odysseus/Bureau/ANR/testsCode/testChElem/'), '*.xml')):\n",
    "    fileTemp=fileTemp.replace(\"/\",\":\")\n",
    "    tei = open('/home/odysseus/Bureau/ANR/testsCode/testChElem/'+fileTemp).read()\n",
    "    xmlSoup = soup(tei, 'html.parser')\n",
    "    for element in xmlSoup(text=lambda text: isinstance(text, Comment)):\n",
    "        element.extract()\n",
    "\n",
    "# Nettoyage des dublin core :\n",
    "    for a in xmlSoup.find_all(\"dc:creator\"):\n",
    "        a.name=\"author\"\n",
    "        del a[\"opf:file-as\"]\n",
    "        del a[\"xmlns:dc\"]\n",
    "        del a[\"xmlns:opf\"]\n",
    "        del a[\"opf:role\"]\n",
    "    for a in xmlSoup.find_all(\"dc:date\"):\n",
    "        a.name=\"date\"\n",
    "        cutDate=a.string\n",
    "        a.string=cutDate[:4]\n",
    "        del a[\"xmlns:dc\"]\n",
    "    for a in xmlSoup.find_all(\"dc:subject\"):\n",
    "        a.name=\"subject\"\n",
    "        a.attrs.clear()\n",
    "    for a in xmlSoup.find_all(\"dc:title\"):\n",
    "        a.name=\"title\"\n",
    "        del a[\"xmlns:dc\"]\n",
    "\n",
    "# italiques\n",
    "    for a in xmlSoup.find_all(\"hi\"):\n",
    "        a.attrs.clear()\n",
    "        a[\"rend\"]=\"italic\"\n",
    "    for a in xmlSoup.find_all(\"emph\"):\n",
    "        a.name=\"hi\"\n",
    "        a.attrs.clear()\n",
    "        a[\"rend\"]=\"italic\"\n",
    "\n",
    "# dedication\n",
    "    for a in xmlSoup.find_all('quote',{\"rend\" : \"epigraphe\"}):\n",
    "        if a[\"rend\"]==\"epigraphe\":\n",
    "            a.name=\"div\"\n",
    "            text=\"\"\n",
    "            del a[\"rend\"]\n",
    "            if a.findChildren() : \n",
    "                for b in a.findChildren():\n",
    "                    if not b.findChildren():\n",
    "                        text+=b.string\n",
    "            else :\n",
    "                text+=a.string\n",
    "            a.clear()\n",
    "            a[\"type\"]=\"dedication\"\n",
    "            newTag=xmlSoup.new_tag('epigraph')\n",
    "            newTag.string=text\n",
    "            a.append(newTag)\n",
    "\n",
    "# clear <p>s\n",
    "    for a in xmlSoup.find_all('p'):\n",
    "        a.attrs.clear()\n",
    "        a.name=\"p\"\n",
    "\n",
    "# quotes, citations\n",
    "    quote(xmlSoup,quotes,\"quotecit\")\n",
    "    quote(xmlSoup,verses,\"quoteverse\")\n",
    "    \n",
    "            \n",
    "# nettoyer balise head   \n",
    "    for a in xmlSoup.find_all('head'):\n",
    "        a.attrs.clear()\n",
    "    for a in xmlSoup.find_all('head'):\n",
    "        test=a.text\n",
    "        if \"À propos de cette édition numérique\" in test:\n",
    "            a.extract()\n",
    "\n",
    "# nettoyer les div rend\n",
    "    divRend(xmlSoup,rends,\"p\")\n",
    "    quote(xmlSoup,salutes,\"salute\")\n",
    "    \n",
    "    for a in xmlSoup.find_all('div',{\"rend\" : \"letter\"}):\n",
    "        a.attrs.clear()\n",
    "        a.name=\"q\"\n",
    "        a[\"type\"]=\"letter\"\n",
    "\n",
    "# chapitres, parties, livres\n",
    "    defChap()\n",
    "\n",
    "# inclassables\n",
    "    for a in xmlSoup.find_all('div',{\"type\" : \"section\"}):\n",
    "        test=a[\"n\"]\n",
    "        if \"START: FULL LICENSE\" or \"propos de cette édition numérique\" in test:\n",
    "            a.extract()\n",
    "        \n",
    "    for a in xmlSoup.find_all('ref',{\"rend\" : \"renvoi\"}):\n",
    "        if xmlSoup.find('div', {\"rend\":\"notecnt\"}):\n",
    "            elemTarg=xmlSoup.find('div', {\"rend\":\"notecnt\"})\n",
    "            a.name=\"note\"\n",
    "            a.attrs.clear()\n",
    "            strChild=\"\"\n",
    "            if elemTarg.findChildren:\n",
    "                for child in elemTarg.findChildren():\n",
    "                    strChild+=\" \"+child.string\n",
    "            else:\n",
    "                strChild=elemTarg.string\n",
    "            a.string=strChild\n",
    "            elemTarg.extract()\n",
    "        \n",
    "# suppressions    \n",
    "    elemExtract(toRem)\n",
    "    [x.extract() for x in xmlSoup.findAll('div',{'rend':\"som\"})]\n",
    "    [x.extract() for x in xmlSoup.findAll('div', {\"rend\":\"illustypeimage\"})]\n",
    "    [x.extract() for x in xmlSoup.findAll('div', {\"rend\":\"realspc\"})]\n",
    "    [x.extract() for x in xmlSoup.findAll('div', {\"rend\":\"pblanc\"})]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1056,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lxml.html.soupparser import fromstring\n",
    "from lxml import etree, objectify\n",
    "from lxml.etree import tostring\n",
    "from lxml.etree import QName\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1057,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from io import StringIO, BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1058,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "root=str(xmlSoup)\n",
    "myparser = etree.XMLParser(remove_blank_text=True)\n",
    "tree   = etree.parse(StringIO(root), parser=myparser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1059,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tei= etree.Element('TEI')\n",
    "\n",
    "teiHeader=etree.Element('teiHeader')\n",
    "\n",
    "text=etree.Element('text')\n",
    "\n",
    "back=etree.Element('back')\n",
    "body=etree.Element('body')\n",
    "front=etree.Element('front')\n",
    "\n",
    "fileDesc=etree.Element('fileDesc')\n",
    "\n",
    "titleStmt=etree.Element('titleStmt')\n",
    "title=etree.Element('title')\n",
    "title.text=tree.find('.//{http://www.tei-c.org/ns/1.0}title').text\n",
    "author=etree.Element('author', \n",
    "                     attrib=OrderedDict([ \\\n",
    "                        (\"key\",\"\"), \\\n",
    "                        (\"name\",tree.find('.//{http://www.tei-c.org/ns/1.0}author').text),\\\n",
    "                        (\"from\",tree.find('.//{http://www.tei-c.org/ns/1.0}date').text),\\\n",
    "                        (\"to\",tree.find('.//{http://www.tei-c.org/ns/1.0}date').text)]))\n",
    "attEdition = {\"n\":\"\"}\n",
    "edition=etree.Element('edition', attrib=attEdition)\n",
    "\n",
    "editor=etree.Element('editor',attrib=OrderedDict([(\"name\",\"\"),(\"where\",\"\")]))\n",
    "titleStmt.append(title)\n",
    "titleStmt.append(author)\n",
    "titleStmt.append(edition)\n",
    "titleStmt.append(editor)\n",
    "\n",
    "publicationStmt=etree.Element('publicationStmt')\n",
    "myattributes2 = {\"when\": tree.find('.//{http://www.tei-c.org/ns/1.0}date').text,\n",
    "                 \"type\": \"issued\"}\n",
    "myattributes1 = {\"when\": tree.find('.//{http://www.tei-c.org/ns/1.0}date').text,\n",
    "                 \"type\": \"created\"}\n",
    "date1=etree.Element('date', attrib=myattributes1)\n",
    "date2=etree.Element('date', attrib=myattributes2)\n",
    "publicationStmt.append(date1)\n",
    "publicationStmt.append(date2)\n",
    "\n",
    "editionStmt=etree.Element('editionStmt')\n",
    "canon=\"\"\n",
    "listSubjects=tree.findall(\".//{http://www.tei-c.org/ns/1.0}subject\")\n",
    "keywords=etree.Element('keywords')\n",
    "for a in listSubjects:\n",
    "    if \"canonique\" in a.text:\n",
    "        canon=\"canonique\"\n",
    "    else:\n",
    "        canon=\"non-canonique\"\n",
    "        term=etree.Element(\"term\")\n",
    "        keywords.append(term)\n",
    "attProfDesc = {\"type\":\"\",\"tag\":canon}\n",
    "profileDesc=etree.Element('profileDesc', attrib=OrderedDict([(\"type\",\"genre\"),(\"tag\",\"canon\")]))\n",
    "textClass=etree.Element('textClass')\n",
    "\n",
    "textClass.append(keywords)\n",
    "profileDesc.append(textClass)\n",
    "editionStmt.append(profileDesc)\n",
    "\n",
    "fileDesc.append(titleStmt)\n",
    "fileDesc.append(publicationStmt)\n",
    "fileDesc.append(editionStmt)\n",
    "\n",
    "titlePage=etree.Element('titlePage')\n",
    "docAuthor=etree.Element('docAuthor')\n",
    "docTitle=etree.Element('docTitle')\n",
    "attTitPart1={\"main\":title.text}\n",
    "attTitPart2={\"sub\":\"\"}\n",
    "titlePart1=etree.Element('titlePart',attrib=attTitPart1)\n",
    "titlePart2=etree.Element('titlePart',attrib=attTitPart2)\n",
    "docTitle.append(titlePart1)\n",
    "docTitle.append(titlePart2)\n",
    "titlePage.append(docAuthor)\n",
    "titlePage.append(docTitle)\n",
    "\n",
    "attDed={\"type\":\"dedication\"}\n",
    "divDed=etree.Element('div', attrib=attDed)\n",
    "listSalutes=tree.findall(\".//{http://www.tei-c.org/ns/1.0}salute\")\n",
    "for salute in listSalutes:\n",
    "    newSal=etree.Element('salute')\n",
    "    tmpSal=salute.text.strip()\n",
    "    newSal.text=tmpSal\n",
    "    divDed.append(newSal)\n",
    "listDedications=tree.findall(\".//{http://www.tei-c.org/ns/1.0}dedication\")\n",
    "for dedication in listDedications:\n",
    "    divDed.append(dedication)\n",
    "if divDed.getchildren():\n",
    "    titlePage.append(divDed)\n",
    "\n",
    "attPref={\"type\":\"preface\"}\n",
    "divPref=etree.Element('div', attrib=attPref)\n",
    "preface=\"\"\n",
    "# attention, passage à tester sur un texte à préface\n",
    "listPref=tree.xpath('//div[re:test(@n, \"^préface$\", \"i\")]',\n",
    "                      namespaces={\"re\": \"http://exslt.org/regular-expressions\"})\n",
    "if len(listPref)==1:\n",
    "    prefElem=listPref(0)\n",
    "    preface=prefElem.text\n",
    "elif len(listPref)>1:\n",
    "    for prefElem in listPref:\n",
    "        preface+=prefElem.text+\" \"\n",
    "divPref.text=preface\n",
    "if divPref.getchildren():\n",
    "    titlePage.append(divPref)\n",
    "\n",
    "front.append(titlePage)\n",
    "text.append(front)\n",
    "\n",
    "head=etree.Element('head')\n",
    "listQuotes=tree.findall(\".//{http://www.tei-c.org/ns/1.0}quotecit\")\n",
    "for quote in listQuotes:\n",
    "    quote.name=\"quote\"\n",
    "    if quote.text and quote.getchildren()==False:\n",
    "        parag=etree.Element('p')\n",
    "        tmp=re.sub(r'(\\s+)', ' ', quote.text).strip()\n",
    "        parag.text=tmp\n",
    "        quote.text=\"\"\n",
    "        quote.append(parag)\n",
    "listVerse=tree.findall(\".//{http://www.tei-c.org/ns/1.0}quoteverse\")\n",
    "for quote in listVerse:\n",
    "        \n",
    "    if quote.getchildren():\n",
    "        for element in quote.getchildren():\n",
    "            element.tag=\"q\"\n",
    "    else:\n",
    "        parag=etree.Element('q')\n",
    "        tmp=re.sub(r'(\\s+)', ' ', quote.text).strip()\n",
    "        parag.text=tmp\n",
    "        quote.text=\"\"\n",
    "        quote.append(parag)\n",
    "    quote.tag=\"quote\"\n",
    "    \n",
    "listBooks=tree.findall(\".//{http://www.tei-c.org/ns/1.0}subject\")\n",
    "book=etree.Element('div', \n",
    "                   attrib=OrderedDict(\n",
    "        [(\"type\",\"book\"),(\"title\",\"\"),(\"level\",\"1\")]))\n",
    "listBook=tree.findall(\".//{http://www.tei-c.org/ns/1.0}book\")\n",
    "listPart=tree.findall(\".//{http://www.tei-c.org/ns/1.0}part\")\n",
    "if len(listPart)>0:\n",
    "    for part in listPart:\n",
    "        part=etree.Element('part')\n",
    "        chapInPart=part.findall(\".//{http://www.tei-c.org/ns/1.0}chapter\")\n",
    "        for chap in chapInPart:\n",
    "            part.append(chap)\n",
    "        body.append(part)\n",
    "if len(listBook)>0:\n",
    "    for book in listBook:\n",
    "        part=etree.Element('book')\n",
    "        chapInPart=part.findall(\".//{http://www.tei-c.org/ns/1.0}chapter\")\n",
    "        if len(chapInPart)>0:\n",
    "            for chap in chapInPart:\n",
    "                part.append(chap)\n",
    "        else:\n",
    "            part=book\n",
    "        body.append(part)\n",
    "else :\n",
    "    listChap=tree.findall(\".//{http://www.tei-c.org/ns/1.0}chapter\")\n",
    "    for chap in listChap:\n",
    "        body.append(chap)\n",
    "# #     if len(listChap)<1:\n",
    "#     listSect=tree.findall(\".//{http://www.tei-c.org/ns/1.0}UndefinedSection\")\n",
    "#     for sect in listSect:\n",
    "#         body.append(sect)\n",
    "body.append(head)\n",
    "text.append(body)\n",
    "\n",
    "text.append(back)\n",
    "tei.append(teiHeader)\n",
    "tei.append(text)\n",
    "teiHeader.append(fileDesc)\n",
    "\n",
    "for element in tei.iter():\n",
    "    element.tail = None\n",
    "\n",
    "final=str(etree.tostring(tei, pretty_print=True,encoding = \"unicode\"))\n",
    "final = re.sub(r'ns[0-9]+:', '', final)\n",
    "final= final.replace(\"&#10;\",\"\")\n",
    "final=re.sub(r'xmlns:ns[0-9]+=\\\"http://www.tei-c.org/ns/1.0\\\" ',\"\",final)\n",
    "f = open('test.xml', 'w')\n",
    "f.write(final)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
